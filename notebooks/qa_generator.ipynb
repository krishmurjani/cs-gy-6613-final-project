{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SECRET_KEY = os.getenv(\"API_SECRET_KEY\", \"replace-with-your-api-key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e261113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_mock_data(count=100):\n",
    "    sample_data = []\n",
    "    for idx in range(count):\n",
    "        sample_data.append({\n",
    "            \"doc_text\": f\"Sample content {idx} related to robotics and AI systems.\",\n",
    "            \"doc_title\": f\"Document {idx}\",\n",
    "            \"doc_platform\": \"Robotics Tech Framework\",\n",
    "            \"doc_links\": {\n",
    "                \"reference_url\": \"https://sampledomain.com/doc\"\n",
    "            },\n",
    "            \"doc_language\": \"en\"\n",
    "        })\n",
    "    return sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_process():\n",
    "    total_iterations = 2\n",
    "    segment_size = 2\n",
    "\n",
    "    records = fetch_mock_data(count=total_iterations * segment_size)\n",
    "    print(f\"Starting process with {total_iterations} iterations of size {segment_size}\")\n",
    "\n",
    "    output_data = []\n",
    "    token_usage = 0\n",
    "\n",
    "    assistant_prompt = \"\"\"You are an AI that specializing in generating QA pairs from provided content regarding Robotics. \n",
    "    Instructions:\n",
    "    - Develop queries as a typical user might ask, incorporating informal language if relevant.\n",
    "    - Ensure responses are comprehensive and precise, referencing the context.\n",
    "    - Provide step-by-step solutions where applicable.\n",
    "    - Questions must remain context-specific, balancing general and detailed levels.\n",
    "    - Create 2 basic-level and 2 advanced-level questions per context.\n",
    "    - Diversify content and avoid repetitions.\n",
    "    \"\"\"\n",
    "\n",
    "    for idx in tqdm(range(min(total_iterations, len(records) // segment_size)), desc=\"Processing data\"):\n",
    "        subset = records[idx * segment_size:(idx + 1) * segment_size]\n",
    "        print(f\"Processing segment {idx+1}/{total_iterations}\")\n",
    "\n",
    "        documentation = \"\"\n",
    "        for count, record in enumerate(subset):\n",
    "            documentation += f\"Source {count+1}:\n",
    "\"\n",
    "            documentation += f\"Content: {record['doc_text']}\n",
    "\"\n",
    "            documentation += f\"Title: {record.get('doc_title', 'Not Available')}\n",
    "\"\n",
    "            documentation += f\"Platform: {record.get('doc_platform', 'Not Available')}\n",
    "\"\n",
    "            documentation += f\"Reference URL: {record.get('doc_links', {}).get('reference_url', 'Not Available')}\n",
    "\"\n",
    "            documentation += f\"Language: {record.get('doc_language', 'Not Available')}\n",
    "\"\n",
    "            documentation += \"-\" * 50 + \"\\n\"\n",
    "\n",
    "        user_query = f\"\"\"Based on these documents, generate 4 Q&A pairs according to the provided guidelines. \n",
    "        Use the source content to ensure accuracy and natural flow.\n",
    "        Document Content:\n",
    "        {documentation}\"\"\"\n",
    "\n",
    "        request_headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {SECRET_KEY}\"\n",
    "        }\n",
    "\n",
    "        request_payload = {\n",
    "            \"model\": \"gpt-4-0613\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": assistant_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_query}\n",
    "            ],\n",
    "            \"temperature\": 1,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"top_p\": 1,\n",
    "            \"frequency_penalty\": 0.5,\n",
    "            \"presence_penalty\": 0.5\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=request_headers, json=request_payload)\n",
    "            response.raise_for_status()\n",
    "            api_result = response.json()\n",
    "\n",
    "            if 'usage' in api_result:\n",
    "                prompt_tokens = api_result['usage'].get('prompt_tokens', 0)\n",
    "                completion_tokens = api_result['usage'].get('completion_tokens', 0)\n",
    "                token_usage += prompt_tokens + completion_tokens\n",
    "                print(f\"Tokens Used - Prompt: {prompt_tokens}, Completion: {completion_tokens}\")\n",
    "\n",
    "            response_content = api_result['choices'][0]['message']['content']\n",
    "            generated_pairs = json.loads(response_content)['qa_pairs']\n",
    "            output_data.extend(generated_pairs)\n",
    "\n",
    "            print(f\"Generated {len(generated_pairs)} pairs for segment {idx+1}\")\n",
    "\n",
    "            time.sleep(1)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error processing segment {idx+1}: {str(ex)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Total tokens used: {token_usage}\")\n",
    "    print(json.dumps({\"qa_pairs\": output_data}, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    execute_process()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
